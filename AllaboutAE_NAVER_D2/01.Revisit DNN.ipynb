{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Revisit Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1](./img/img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전통적인 ML에서는 모델 종류와 Loss function에 대해 정의해줘야 한다.\n",
    "* 모델을 정하면 그 모델을 결정지을 parameter를 추정해야하는데 이 parameter를 학습하는 과정이 보통의 학습과정이다.\n",
    "* 이 때 parameter를 theta라 하면 모델의 출력값과 실제값의 차이가 얼마나 다르냐를 정의한 것이 Loss function. \n",
    "* Loss function이 최소가 되는 theta값을 찾아가는 것이 학습의 과정이다.\n",
    "* ***고정된 입력값에 대해서는 고정된 출력값이 나온다***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img2](./img/img2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 여기서 DNN은 모델의 종류를 의미한다. f에 해당.\n",
    "* DNN에서 Loss function은 MSE(Mean Squared Error) or Crossentropy 만 사용한다. WHY??(거의)\n",
    "* 대부분의 DNN이 Backpropagation(이하에서 Backpropa) 을 통해 학습이 되는데 Backpropa는 2가지 가정을 가지고 있고 이 가정을 만족하는 Loss    Function 만 사용할 수 있기 때문이다. 가정은 다음과 같다.\n",
    "* ![img3](./img/img3.png)\n",
    "    1. Total loss of DNN over training samples is the sum of loss for each training sample.**(training 샘플 전체의 Loss값 = 각각 샘플의 Loss의 합)**\n",
    "    1. Loss for each training example is a function of final output of DNN.(Loss function의 입력인자는 **네트워크 종단의 출력값과 정답값으로만 구성.** 즉, 네트워크 중간 레이어에서 나온 출력값은 사용하지 않는다. Googlenet의 경우 중간값을 사용하는 것처럼 보이지만 종단이라고 생각하고 뒤로 Backpropa 한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training/Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training데이터 전체에 대한 Loss를 최소화하는 theta를 찾는데 대부분 Gradient Descent 를 사용한다.\n",
    "- G.D는 Iterative Method. 점차적으로 solution을 찾는 방법. 여기에는 2가지 정의가 필요하다.\n",
    "    1. theta를 어떻게 update 할 것인가?\n",
    "        - Loss가 줄어들기만 하면 theta를 update\n",
    "    1. 언제 update를 멈출 것인가?\n",
    "        - theta를 갱신해도 Loss가 줄어들지 않으면 stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But, 우리가 다루는 DNN에서 theta의 dimension은 매우 크다. 그렇다면 **어떻게 theta를 바꿔야 loss가 줄어드는 쪽으로 이동할까?**\n",
    "- ![img4](./img/img4.png)\n",
    "- Taylor expansion의 근삿값으로 1차미분 term까지만 사용한다. 더 많은 차수의 미분 term을 사용할수록 더 넓은 범위에서 오차가 줄어든다.\n",
    "- 1차 미분 term까지만 사용하는 의미 : 그 데이터 포인트 근방에서는 오차가 거의 없다. 거의 같은 값으로 보인다.\n",
    "- Approximation에서 L(theta)를 좌변으로 이항하면 그 좌변(delta L)이 음수가 돼야 loss가 줄어드는것이다. 따라서 Gradient(L)*delta(theta)를 음수로 만들어야 한다. How??\n",
    "    - delta(theta)가 -Gradient(L) 이면 delta(L)은 항상 음수가 된다. 위 식에서 eta는 learning rate로 항상 양수인 수다.\n",
    "    - 여기서 learning rate를 항상 작은 값(0.001, 0.01 etc.)을 사용하는 이유를 알 수 있다. \n",
    "        - loss가 감소하려면 delta(theta)=-Gradient 여야 한다. 그러면 어떤 Gradient 값을 쓸 것인가? Approximation에서 1차미분값까지만 사용했으므로 **데이터 포인트 근방의 Gradient값**이어야 감소 방향의 오차가 줄어든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ![img5](./img/img5.png)\n",
    "- Line 1 은 Backpropa의 가정이므로 성립한다고 치면 그것의 Gradient값에 대해서도 성립\n",
    "- 최적화 문제에서 상수배하거나 상수 term을 더하는 것은 영향을 주지 않음(training 중간에 데이터 개수가 변하지 않는다는 가정하에). 따라서 우변을 데이터 개수로 나누면 Line 3에서 우변은 sample별 평균 Gradient 를 의미.\n",
    "- But, 데이터 개수가 너무 크기 때문에 batch를 사용한다. 전체 training데이터셋의 평균 Gradient 와 training셋에서 M개를 임의추출하여 구한 M개의 평균 Gradient 값이 같을 것이라고 기대. -> Stochastic G.D\n",
    "- 이렇게 구한 Gradient를 가지고 theta(weight, bias)를 갱신한다.\n",
    "- 정리하면 **원래 전체 training DB에 대한 Gradient를 구해야 하지만 연산량이 너무 많기 때문에 평균 Gradient를 사용하고 여기서 또 전체에 대한 평균이 아니라 batch의 평균을 사용한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ![img6](./img/img6.png)\n",
    "- output layer에서 Error signal은 네트워크 출력값에 대한 Loss function의 미분값에 Activation function의 미분값(activate function 입력값에 대한)을 곱한 값이다. 여기서 곱은 element-wise 곱.\n",
    "- bias에 대한 Gradient 값은 Error signal\n",
    "- weight에 대한 Gradient 값은 Error signal*해당layer입력값\n",
    "- ref) http://neuralnetworksanddeeplearning.com/chap2.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function viewpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss function중에서 MSE와 Cross Entropy 중 어떤 것이 더 좋은가?? \n",
    "- 두 가지 관점에서 볼 수 있다. \n",
    "    1. Backpropagation 알고리즘이 잘 동작하는 관점 : Cross Entropy가 더 좋다.\n",
    "    1. **Maximum likilihood 관점 : 출력값이 continuous value 이면 MSE, discrete value이면 Cross Entropy가 좋다.**\n",
    "- 두 가지 관점에서 봤을때 이러한 해석이 있다는 것이지 맞다는 것은 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function viewpoint 1 : Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아주 간단한 NN모델을 예시로 보자.\n",
    "- ![img7](./img/img7.png)\n",
    "- 위 모델을 학습하는 과정에서 loss function이 MSE이면 W,b의 초기값이 학습에 많은 영향을 끼친다. WHY?\n",
    "    - Error Signal 수식을 보면 activation function 미분 term이 살아있는데 sigmoid 함수의 미분값은 커봤자 약 0.25정도이다.\n",
    "    - 위의 경우 activation function이 sigmoid 함수인데 초기값에 따라서 Gradient값이 차이가 있다. 초기값이 sigmoid의 미분값이 거의 0인 지점이라면 Gradient값이 거의 0이므로 학습이 매우 느리게 될 수 있다. \n",
    "    - 이 문제는 레이어가 깊을수록(Deep NN을 구성하게 되면) 한 레이어당 Error Signal에 0.25(최대일때)가 계속 곱해지게 되고 입력단 근처에 가면 결국 Error Signal은 0에 가까운 값이 되어서 학습이 안된다.(Vanishing Gradient Problem)\n",
    "        - 즉 activation function의 미분값에 영향을 받게 된다. sigmoid함수의 문제를 해결하기 위해 사용되는 것이 ReLU함수. But, 무조건 좋다는 것은 아니다. ***Backpropa 동작 관점에서는*** ReLU가 좋다는것. \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img9](./img/img9.png)\n",
    "- 반면 Cross Entropy함수일때 Error Signal을 구해보면 위 표처럼 절묘하게 activation function 미분 term이 사라지게 된다.\n",
    "- 이에 따라서 MSE와 비교했을때 상대적으로 Vanishing Gradient Problem에서 자유롭다.\n",
    "![img10](./img/img10.png)\n",
    "- loss function에 따라서 학습되는 정도에 차이를 보이는 것을 그래프를 통해 알 수 있다.\n",
    "- 확실히 Cross Entropy 일때는 초기값에 영향을 덜 받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function viewpoint 2 : Maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img11](./img/img11.png)\n",
    "- 네트워크 출력값이 있을때 우리가 원하는 정답이 나올 확률이 높기를 바란다. 확률을 Maximize. 따라서 확률분포모델을 정하고 간다.\n",
    "- 확률분포를 가우시안 분포라고 가정해서 예를 들면(위 그래프에서) 확률분포를 정하기 위한 parameter를 추정하는 것이다. 즉 가우시안이면 평균, 표준편차를 추정하기 위한것.\n",
    "    - 언제 Maximum likelihood가 될까?\n",
    "    - **네트워크 출력값 분포의 평균이 y가 될때 최대** (해석을 이렇게 한다)\n",
    "- ![img12](./img/img12.png)\n",
    "- loss function에 log를 씌운 것은 Backpropa 가정을 만족하기 위해서\n",
    "- 결과적으로 우리가 찾은 것은 확률분포모델을 찾은것.\n",
    "    - Sampling이 가능해진다. 고정입력/고정출력이 아닌 고정입력/**다른 출력** but, MLE를 하면 고정출력으로 볼 수 있다. \n",
    "    - VAE를 확률적 관점으로 해석하는 이유\n",
    "- $p(y|f_{\\\\theta}(x))$에 i.i.d condition을 적용하면 Backpropa의 두가지 조건을 만족하게 된다.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img12](./img/img13.png)\n",
    "- 확률분포모델을 가우시안으로 가정하고 풀면 결국 loss function은 MSE와 같은 결과가 나온다. 베르누이로 가정하고 풀면 Cross Entropy와 같은 결과.\n",
    "- 네트워크 출력값에 대한 확률분포가 가우시안을 따르면 MSE, 베르누이 분포를 따르면 Cross Entropy를 쓰는게 맞다는 해석이 가능.(수식상)\n",
    "- 일반적으로 연속형자료는 가우시안으로 모델링하고 이산형자료는 베르누이로 모델링한다.\n",
    "- 따라서 이런 물음에 답이 가능. \n",
    "    - 연속형 자료일때 왜 loss function을 MSE를 쓰는가? because, 네트워크 출력값의 분포를 가우시안으로 가정하기 때문. \n",
    "- 다변수일때도 동일한 결과가 나옴. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img14](./img/img14.png)\n",
    "- 확률적 관점에서 해석할 때 네트워크 출력값은 likelihood값이 아니다\n",
    "- 그 확률분포를 정하는 Parameter를 추정하는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img15](./img/img15.png)\n",
    "- Yoshua Bengio 교수가 설명한 NN의 log likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lecture : https://www.youtube.com/watch?v=o_peo6U7IRM&t=2545s (오토인코더의 모든것-1/3)\n",
    "- slide : https://www.slideshare.net/NaverEngineering/ss-96581209"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
