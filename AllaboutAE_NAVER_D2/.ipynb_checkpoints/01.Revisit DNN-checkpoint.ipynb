{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Revisit Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1](./img/img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전통적인 ML에서는 모델 종류와 Loss function에 대해 정의해줘야 한다.\n",
    "* 모델을 정하면 그 모델을 결정지을 parameter를 추정해야하는데 이 parameter를 학습하는 과정이 보통의 학습과정이다.\n",
    "* 이 때 parameter를 theta라 하면 모델의 출력값과 실제값의 차이가 얼마나 다르냐를 정의한 것이 Loss function. \n",
    "* Loss function이 최소가 되는 theta값을 찾아가는 것이 학습의 과정이다.\n",
    "* ***고정된 입력값에 대해서는 고정된 출력값이 나온다***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img2](./img/img2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 여기서 DNN은 모델의 종류를 의미한다. f에 해당.\n",
    "* DNN에서 Loss function은 MSE(Mean Squared Error) or Crossentropy 만 사용한다. WHY??(거의)\n",
    "* 대부분의 DNN이 Backpropagation(이하에서 Backpropa) 을 통해 학습이 되는데 Backpropa는 2가지 가정을 가지고 있고 이 가정을 만족하는 Loss    Function 만 사용할 수 있기 때문이다. 가정은 다음과 같다.\n",
    "* ![img3](./img/img3.png)\n",
    "    1. Total loss of DNN over training samples is the sum of loss for each training sample.**(training 샘플 전체의 Loss값 = 각각 샘플의 Loss의 합)**\n",
    "    1. Loss for each training example is a function of final output of DNN.(Loss function의 입력인자는 **네트워크 종단의 출력값과 정답값으로만 구성.** 즉, 네트워크 중간 레이어에서 나온 출력값은 사용하지 않는다. Googlenet의 경우 중간값을 사용하는 것처럼 보이지만 종단이라고 생각하고 뒤로 Backpropa 한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training/Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training데이터 전체에 대한 Loss를 최소화하는 theta를 찾는데 대부분 Gradient Descent 를 사용한다.\n",
    "- G.D는 Iterative Method. 점차적으로 solution을 찾는 방법. 여기에는 2가지 정의가 필요하다.\n",
    "    1. theta를 어떻게 update 할 것인가?\n",
    "        - Loss가 줄어들기만 하면 theta를 update\n",
    "    1. 언제 update를 멈출 것인가?\n",
    "        - theta를 갱신해도 Loss가 줄어들지 않으면 stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function viewpoint 1 : Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function viewpoint 2 : Maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum likelihood for AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
