{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05.Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder는 Dimension Reduction 관점에서 다른 방법론들보다 우수한 성능을 보인다. 데이터 타입에 관계없이 Feature들을 잘 뽑는다. 그래서 Retrieval로 많이 쓰인다.\n",
    "- Text\n",
    "    - [Semantic Hashing](http://www.cs.utoronto.ca/~rsalakhu/papers/semantic_final.pdf)     \n",
    "    - [Dynamic Auto-Encoders for Semantic Indexing](http://yann.lecun.com/exdb/publis/pdf/mirowski-nipsdl-10.pdf)     \n",
    "- Image\n",
    "    - [Using Very Deep Autoencoders for Content-Based Image Retrieval](http://nuyoo.utm.mx/~jjf/rna/A6%20Using%20Very%20Deep%20Autoencoders%20for%20Content-Based%20Image%20Retrieval.pdf)\n",
    "    - [Autoencoding the Retrieval Relevance of Medical Images](https://arxiv.org/pdf/1507.01251.pdf)\n",
    "- Sound\n",
    "    - [Retrieving Sounds by Vocal Imitation Recognition](http://www.ece.rochester.edu/~zduan/resource/ZhangDuan_RetrievingSoundsByVocalImitationRecognition_MLSP15.pdf)\n",
    "- 3D model\n",
    "    - [Deep Learning Representation using Autoencoder for 3D Shape Retrieval](https://arxiv.org/pdf/1409.7164.pdf)\n",
    "    - [Deep Signatures for Indexing and Retrieval in Large Motion Databases](http://web.cs.ucdavis.edu/~neff/papers/MIG_2015_DeepSignature.pdf)\n",
    "    - [DeepShape: Deep Learned Shape Descriptor for 3D Shape Matching and Retrieval](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Xie_DeepShape_Deep_Learned_2015_CVPR_paper.pdf)\n",
    "- Multi-modal\n",
    "    - [Cross-modal Retrieval with Correspondence Autoencoder](https://people.cs.clemson.edu/~jzwang/1501863/mm2014/p7-feng.pdf)\n",
    "    - [Effective multi-modal retrieval based on stacked autoencoders](http://www.comp.nus.edu.sg/~ooibc/crossmodalvldb14.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Gray Face Generation](http://vdumoulin.github.io/morphing_faces/online_demo.html)\n",
    "- [Handwritten Digits Generation](http://www.dpkingma.com/sgvb_mnist_demo/demo.html)\n",
    "- [Sketch RNN](https://magenta.tensorflow.org/sketch-rnn-demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN+VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img50](./img/img50.png)\n",
    "- VAE와 GAN은 생성모델을 학습하고 확률 분포를 추정한다는 관점에서는 같지만 접근방법이 다르다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img51](./img/img51.png)\n",
    "- 위 그림에서 실선 3개가 실제 이미지 공간의 데이터이다. 그러면 저 실선 3개를 모두 학습하는 것이 완벽하게 확률분포를 익히는 것이라고 할 수 있다.\n",
    "    - VAE는 실선 3개를 잘 아우르는 형태로 학습이 되는 반면 GAN은 실선 1개만 잘 익히면 학습이 끝나버린다.즉, GAN은 일부 mode만 잘 익히는 대신 이미지를 샘플링 했을때 진짜같고 sharp한 이미지가 나오고 VAE는 mode와 mode 사이 영역에서도 이미지를 뽑아낼수 있으므로 blurry하지만 다양한 이미지가 나오게된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주로 만들어낼 데이터에 condition을 주고 싶을때 VAE로 압축한 걸 사용하고 그걸 통해 generation 된 것이 실제와 똑같은 지를 측정하기 위해 Discriminator를 사용하여 GAN loss를 쓰는 방법을 많이 사용한다.(2017년까지 발표된 논문 근거)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### StackGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img52](./img/img52.png)\n",
    "- 입력된 문장에 맞는 이미지를 생성해내는 StackGAN\n",
    "- 입력된 문장을 벡터화 한 다음에 그대로 condition으로 넣는게 아니라 그 벡터중에서도 중요한 feature를 잘 뽑기 위해서 word vector들만 가지고 VAE로 한 번 학습을 시킨다.(Encoder부분만 사용)\n",
    "- 그 결과가 generator에 condition으로 들어간다. 그렇게 생성된 이미지를 다시 압축해서 generator에 한 번 더 태운다.(GAN을 두 번 쓰는 형태라서 StackGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3DGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img53](./img/img53.png)\n",
    "- 2D이미지를 주면 그거에 맞는 3D이미지를 생성해냄.\n",
    "- 마찬가지로 generator에 넣을 condition을 주기 위해 2D이미지를 VAE를 통해 압축을 시킨 뒤 random noise와 함께 generator에 태운다.\n",
    "- 그렇게해서 나온 3D이미지가 진짜인가를 Discriminator가 판별함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에 두가지 케이스 모두 생성할 데이터의 도메인과 다른 도메인을 가진 데이터를 condition으로 넣어줄때 feature를 뽑아주는 역할을 하기 위해 VAE를 사용했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SEGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img54](./img/img54.png)\n",
    "- Denoising역할을 하는 것으로 음성데이터에서 배경noise를 제거해냄."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conditional Adversarial AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img55](./img/img55.png)\n",
    "- 나이가 레이블로 붙어있는 얼굴 이미지 데이터를 학습시켜서 나이에 맞는 얼굴 이미지 데이터를 생성하기 위해 사용한 CAAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 밖에도 많은 논문들이 나오고 있지만 뭔가 혁신적인 것은 나오고 있지 않는것 같다고 하신다. 발전 속도가 워낙 빠르기 때문에 앞으로도 계속 주시해야될 분야라고도 말씀하셨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lecture : https://www.youtube.com/watch?v=LeVkjCuUdRs&t=25s - 오토인코더의 모든것-(3/3)\n",
    "- slide : https://www.slideshare.net/NaverEngineering/ss-96581209"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
